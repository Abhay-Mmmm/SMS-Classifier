{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa49cb0-69bd-4c7f-bb71-389d93d10c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB with CountVectorizer. Has score: 0.9778156996587031\n",
      "BernoulliNB with TfidfVectorizer. Has score: 0.9778156996587031\n",
      "BernoulliNB with HashingVectorizer. Has score: 0.8728668941979523\n",
      "RandomForestClassifier with CountVectorizer. Has score: 0.9761092150170648\n",
      "RandomForestClassifier with TfidfVectorizer. Has score: 0.9761092150170648\n",
      "RandomForestClassifier with HashingVectorizer. Has score: 0.9709897610921502\n",
      "AdaBoostClassifier with CountVectorizer. Has score: 0.947098976109215\n",
      "AdaBoostClassifier with TfidfVectorizer. Has score: 0.9539249146757679\n",
      "AdaBoostClassifier with HashingVectorizer. Has score: 0.9505119453924915\n",
      "BaggingClassifier with CountVectorizer. Has score: 0.9641638225255973\n",
      "BaggingClassifier with TfidfVectorizer. Has score: 0.9667235494880546\n",
      "BaggingClassifier with HashingVectorizer. Has score: 0.9658703071672355\n",
      "ExtraTreesClassifier with CountVectorizer. Has score: 0.9778156996587031\n",
      "ExtraTreesClassifier with TfidfVectorizer. Has score: 0.9778156996587031\n",
      "ExtraTreesClassifier with HashingVectorizer. Has score: 0.9701365187713311\n",
      "GradientBoostingClassifier with CountVectorizer. Has score: 0.9709897610921502\n",
      "GradientBoostingClassifier with TfidfVectorizer. Has score: 0.9650170648464164\n",
      "GradientBoostingClassifier with HashingVectorizer. Has score: 0.9718430034129693\n",
      "DecisionTreeClassifier with CountVectorizer. Has score: 0.9650170648464164\n",
      "DecisionTreeClassifier with TfidfVectorizer. Has score: 0.96160409556314\n",
      "DecisionTreeClassifier with HashingVectorizer. Has score: 0.96160409556314\n",
      "CalibratedClassifierCV with CountVectorizer. Has score: 0.9863481228668942\n",
      "CalibratedClassifierCV with TfidfVectorizer. Has score: 0.9863481228668942\n",
      "CalibratedClassifierCV with HashingVectorizer. Has score: 0.9820819112627986\n",
      "DummyClassifier with CountVectorizer. Has score: 0.8728668941979523\n",
      "DummyClassifier with TfidfVectorizer. Has score: 0.8728668941979523\n",
      "DummyClassifier with HashingVectorizer. Has score: 0.8728668941979523\n",
      "PassiveAggressiveClassifier with CountVectorizer. Has score: 0.984641638225256\n",
      "PassiveAggressiveClassifier with TfidfVectorizer. Has score: 0.984641638225256\n",
      "PassiveAggressiveClassifier with HashingVectorizer. Has score: 0.9829351535836177\n",
      "RidgeClassifier with CountVectorizer. Has score: 0.9812286689419796\n",
      "RidgeClassifier with TfidfVectorizer. Has score: 0.9829351535836177\n",
      "RidgeClassifier with HashingVectorizer. Has score: 0.9820819112627986\n",
      "RidgeClassifierCV with CountVectorizer. Has score: 0.9829351535836177\n",
      "RidgeClassifierCV with TfidfVectorizer. Has score: 0.984641638225256\n",
      "RidgeClassifierCV with HashingVectorizer. Has score: 0.9803754266211604\n",
      "SGDClassifier with CountVectorizer. Has score: 0.9863481228668942\n",
      "SGDClassifier with TfidfVectorizer. Has score: 0.9863481228668942\n",
      "SGDClassifier with HashingVectorizer. Has score: 0.984641638225256\n",
      "OneVsRestClassifier with CountVectorizer. Has score: 0.9863481228668942\n",
      "OneVsRestClassifier with TfidfVectorizer. Has score: 0.9880546075085325\n",
      "OneVsRestClassifier with HashingVectorizer. Has score: 0.9829351535836177\n",
      "OneVsRestClassifier with CountVectorizer. Has score: 0.984641638225256\n",
      "OneVsRestClassifier with TfidfVectorizer. Has score: 0.9752559726962458\n",
      "OneVsRestClassifier with HashingVectorizer. Has score: 0.9692832764505119\n",
      "KNeighborsClassifier with CountVectorizer. Has score: 0.9257679180887372\n",
      "KNeighborsClassifier with TfidfVectorizer. Has score: 0.962457337883959\n",
      "KNeighborsClassifier with HashingVectorizer. Has score: 0.9607508532423208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.calibration import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.svm import *\n",
    "import pandas\n",
    "\n",
    "\n",
    "def perform(classifiers, vectorizers, train_data, test_data):\n",
    "    for classifier in classifiers:\n",
    "      for vectorizer in vectorizers:\n",
    "        string = ''\n",
    "        string += classifier.__class__.__name__ + ' with ' + vectorizer.__class__.__name__\n",
    "\n",
    "        # train\n",
    "        vectorize_text = vectorizer.fit_transform(train_data.v2)\n",
    "        classifier.fit(vectorize_text, train_data.v1)\n",
    "\n",
    "        # score\n",
    "        vectorize_text = vectorizer.transform(test_data.v2)\n",
    "        score = classifier.score(vectorize_text, test_data.v1)\n",
    "        string += '. Has score: ' + str(score)\n",
    "        print(string)\n",
    "\n",
    "# open data-set and divide it\n",
    "data = pandas.read_csv('spam.csv', encoding='latin-1')\n",
    "learn = data[:4400] # 4400 items\n",
    "test = data[4400:] # 1172 items\n",
    "\n",
    "perform(\n",
    "    [\n",
    "        BernoulliNB(),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        CalibratedClassifierCV(),\n",
    "        DummyClassifier(),\n",
    "        PassiveAggressiveClassifier(),\n",
    "        RidgeClassifier(),\n",
    "        RidgeClassifierCV(),\n",
    "        SGDClassifier(),\n",
    "        OneVsRestClassifier(SVC(kernel='linear')),\n",
    "        OneVsRestClassifier(LogisticRegression()),\n",
    "        KNeighborsClassifier()\n",
    "    ],\n",
    "    [\n",
    "        CountVectorizer(),\n",
    "        TfidfVectorizer(),\n",
    "        HashingVectorizer()\n",
    "    ],\n",
    "    learn,\n",
    "    test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913bf194-3cff-49a4-b5fb-292beb51a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now know that OneVsRestClassifier works best on our dataset\n",
    "# Vectorizer is TfidVectorizer\n",
    "# Now we try to get each prediction ina more detailed manner.\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.calibration import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.svm import *\n",
    "import pandas\n",
    "import csv\n",
    "\n",
    "data = pandas.read_csv('spam.csv', encoding='latin-1')\n",
    "train_data = data[:4400] # 4400 items\n",
    "test_data = data[4400:] # 1172 items\n",
    "\n",
    "classifier = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# train\n",
    "vectorize_text = vectorizer.fit_transform(train_data.v2)\n",
    "classifier.fit(vectorize_text, train_data.v1)\n",
    "\n",
    "# score\n",
    "# vectorize_text = vectorizer.transform(test_data.v2)\n",
    "# score = classifier.score(vectorize_text, test_data.v1)\n",
    "# print(score) # 98,8\n",
    "\n",
    "\n",
    "csv_arr = []\n",
    "for index, row in test_data.iterrows():\n",
    "    answer = row.iloc[0]\n",
    "    text = row.iloc[1]\n",
    "    vectorize_text = vectorizer.transform([text])\n",
    "    predict = classifier.predict(vectorize_text)[0]\n",
    "    if predict == answer:\n",
    "        result = 'right'\n",
    "    else:\n",
    "        result = 'wrong'\n",
    "    csv_arr.append([len(csv_arr), text, answer, predict, result])\n",
    "\n",
    "\n",
    "# write csv\n",
    "with open('test_score.csv', 'w', newline='',encoding='utf-8') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=';',\n",
    "            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['#', 'text', 'answer', 'predict', 'result'])\n",
    "\n",
    "    for row in csv_arr:\n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07633a-dee7-46b1-ac92-47a995b3acc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
